{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Emotion classification\n",
    "The problem type is supervised multiclass classification and the target is the emotion, with the different classes being ('sadness', 'anger', 'love', 'surprise', 'fear', 'joy').  \n",
    "To do this we're going to apply transfer learning by using a model pre-trained specifically on this task  \n",
    "The model is provided by hugging face\n",
    "https://huggingface.co/mrm8488/t5-base-finetuned-emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1177: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<pad> sadness'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hugging face tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "# load the model which is already trained on emotion dataset\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "# function that takes input and returns emotion\n",
    "def get_emotion(text):\n",
    "  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')\n",
    "\n",
    "  output = model.generate(input_ids=input_ids,\n",
    "               max_length=2)\n",
    "  \n",
    "  dec = [tokenizer.decode(ids) for ids in output]\n",
    "  label = dec[0]\n",
    "  return label\n",
    "  \n",
    "#get_emotion(\"i feel as if i havent blogged in ages are at least truly blogged i am doing an update cute\") # Output: 'joy'\n",
    " \n",
    "get_emotion(\"i have a feeling i kinda lost my best friend\") # Output: 'sadness'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Emoji emotion classification\n",
    "In this part, we're going to use the previous trained model to help us predict the emotions of the emojis. The feature is the emoji name, e.g., FACE WITH TEARS OF JOY. and the target variable is the emotion.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the tweet-emoji dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# the problem with this dataset is that it saves the names of the emojis not the emojis themselves # we will solve this by merging it with another dataset\n",
    "tweets = pd.read_csv(\"../data/new-emojis/tweets_emojis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete uneeded column\n",
    "tweets.drop('Unnamed: 0', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all characters that are not letters or numbers # save it in new column called unicode name to help with merge later\n",
    "tweets['Unicode name'] = tweets['emoji'].str.replace('_', ' ')\n",
    "# convert to upper case\n",
    "tweets['Unicode name']= tweets['emoji'].apply(lambda names: names.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop old column\n",
    "tweets.drop('emoji', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 FACE WITH TEARS OF JOY\n",
       "1                 FACE WITH TEARS OF JOY\n",
       "2                              THUMBS UP\n",
       "3                 FACE WITH TEARS OF JOY\n",
       "4                         CLAPPING HANDS\n",
       "                       ...              \n",
       "1320030                        MALE SIGN\n",
       "1320031    BACKHAND INDEX POINTING RIGHT\n",
       "1320032                     FLUSHED FACE\n",
       "1320033                 PERSON SHRUGGING\n",
       "1320034                    RAISING HANDS\n",
       "Name: Unicode name, Length: 1320035, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['Unicode name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Unicode name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Idk who taught my baby this BS  Ô∏è  IGmeetthesa...</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thats me in every lesson</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are MANY of you  üá∫ üá∏  üá∫ üá∏  üáÆ üá±</td>\n",
       "      <td>THUMBS UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Partner strategy LLRC  Urban naxal theories ar...</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy Birthday More blessings Matsatsi  üèΩ  Hop...</td>\n",
       "      <td>CLAPPING HANDS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            Unicode name\n",
       "0  Idk who taught my baby this BS  Ô∏è  IGmeetthesa...  FACE WITH TEARS OF JOY\n",
       "1                          Thats me in every lesson   FACE WITH TEARS OF JOY\n",
       "2               There are MANY of you  üá∫ üá∏  üá∫ üá∏  üáÆ üá±               THUMBS UP\n",
       "3  Partner strategy LLRC  Urban naxal theories ar...  FACE WITH TEARS OF JOY\n",
       "4  Happy Birthday More blessings Matsatsi  üèΩ  Hop...          CLAPPING HANDS"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the emoji dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Unicode codepoint</th>\n",
       "      <th>Occurrences</th>\n",
       "      <th>Position</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Unicode name</th>\n",
       "      <th>Unicode block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0x1f602</td>\n",
       "      <td>14622</td>\n",
       "      <td>0.805101</td>\n",
       "      <td>3614</td>\n",
       "      <td>4163</td>\n",
       "      <td>6845</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Emoticons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚ù§</td>\n",
       "      <td>0x2764</td>\n",
       "      <td>8050</td>\n",
       "      <td>0.746943</td>\n",
       "      <td>355</td>\n",
       "      <td>1334</td>\n",
       "      <td>6361</td>\n",
       "      <td>HEAVY BLACK HEART</td>\n",
       "      <td>Dingbats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‚ô•</td>\n",
       "      <td>0x2665</td>\n",
       "      <td>7144</td>\n",
       "      <td>0.753806</td>\n",
       "      <td>252</td>\n",
       "      <td>1942</td>\n",
       "      <td>4950</td>\n",
       "      <td>BLACK HEART SUIT</td>\n",
       "      <td>Miscellaneous Symbols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòç</td>\n",
       "      <td>0x1f60d</td>\n",
       "      <td>6359</td>\n",
       "      <td>0.765292</td>\n",
       "      <td>329</td>\n",
       "      <td>1390</td>\n",
       "      <td>4640</td>\n",
       "      <td>SMILING FACE WITH HEART-SHAPED EYES</td>\n",
       "      <td>Emoticons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üò≠</td>\n",
       "      <td>0x1f62d</td>\n",
       "      <td>5526</td>\n",
       "      <td>0.803352</td>\n",
       "      <td>2412</td>\n",
       "      <td>1218</td>\n",
       "      <td>1896</td>\n",
       "      <td>LOUDLY CRYING FACE</td>\n",
       "      <td>Emoticons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emoji Unicode codepoint  Occurrences  Position  Negative  Neutral  Positive  \\\n",
       "0     üòÇ           0x1f602        14622  0.805101      3614     4163      6845   \n",
       "1     ‚ù§            0x2764         8050  0.746943       355     1334      6361   \n",
       "2     ‚ô•            0x2665         7144  0.753806       252     1942      4950   \n",
       "3     üòç           0x1f60d         6359  0.765292       329     1390      4640   \n",
       "4     üò≠           0x1f62d         5526  0.803352      2412     1218      1896   \n",
       "\n",
       "                          Unicode name          Unicode block  \n",
       "0               FACE WITH TEARS OF JOY              Emoticons  \n",
       "1                    HEAVY BLACK HEART               Dingbats  \n",
       "2                     BLACK HEART SUIT  Miscellaneous Symbols  \n",
       "3  SMILING FACE WITH HEART-SHAPED EYES              Emoticons  \n",
       "4                   LOUDLY CRYING FACE              Emoticons  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this dataset to get the emojis\n",
    "emojis = pd.read_csv(\"../data/emojis/Emoji_Sentiment_Data_v1.0.csv\")\n",
    "emojis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we dont need all features, only save emoji and name\n",
    "emojis = emojis[['Emoji', 'Unicode name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Unicode name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚ù§</td>\n",
       "      <td>HEAVY BLACK HEART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‚ô•</td>\n",
       "      <td>BLACK HEART SUIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòç</td>\n",
       "      <td>SMILING FACE WITH HEART-SHAPED EYES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üò≠</td>\n",
       "      <td>LOUDLY CRYING FACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emoji                         Unicode name\n",
       "0     üòÇ               FACE WITH TEARS OF JOY\n",
       "1     ‚ù§                    HEAVY BLACK HEART\n",
       "2     ‚ô•                     BLACK HEART SUIT\n",
       "3     üòç  SMILING FACE WITH HEART-SHAPED EYES\n",
       "4     üò≠                   LOUDLY CRYING FACE"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after\n",
    "emojis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Unicode name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Idk who taught my baby this BS  Ô∏è  IGmeetthesa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Thats me in every lesson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Partner strategy LLRC  Urban naxal theories ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Dont play with me  üèæ ‚Äç  Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>To the goofiest boy ever who apparently looks ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emoji            Unicode name  \\\n",
       "0     üòÇ  FACE WITH TEARS OF JOY   \n",
       "1     üòÇ  FACE WITH TEARS OF JOY   \n",
       "2     üòÇ  FACE WITH TEARS OF JOY   \n",
       "3     üòÇ  FACE WITH TEARS OF JOY   \n",
       "4     üòÇ  FACE WITH TEARS OF JOY   \n",
       "\n",
       "                                                text  \n",
       "0  Idk who taught my baby this BS  Ô∏è  IGmeetthesa...  \n",
       "1                          Thats me in every lesson   \n",
       "2  Partner strategy LLRC  Urban naxal theories ar...  \n",
       "3                         Dont play with me  üèæ ‚Äç  Ô∏è   \n",
       "4  To the goofiest boy ever who apparently looks ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dataset on the unicode name to get a tweet - emoji dataset\n",
    "tweets_emojis = emojis.merge(tweets)\n",
    "tweets_emojis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741777, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_emojis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FACE WITH TEARS OF JOY            210309\n",
       "LOUDLY CRYING FACE                 82659\n",
       "FIRE                               51030\n",
       "FEMALE SIGN                        50941\n",
       "MALE SIGN                          34149\n",
       "WEARY FACE                         30489\n",
       "TWO HEARTS                         30049\n",
       "SMILING FACE WITH SMILING EYES     28519\n",
       "SPARKLES                           23532\n",
       "EYES                               20824\n",
       "FLEXED BICEPS                      16634\n",
       "PURPLE HEART                       16457\n",
       "PARTY POPPER                       16259\n",
       "WINKING FACE                       16075\n",
       "BLUE HEART                         15941\n",
       "SMILING FACE WITH SUNGLASSES       15322\n",
       "SPARKLING HEART                    14614\n",
       "SKULL                              11976\n",
       "CRYING FACE                        11265\n",
       "YELLOW HEART                       10100\n",
       "FLUSHED FACE                        8449\n",
       "WHITE HEAVY CHECK MARK              7192\n",
       "TROPHY                              6892\n",
       "GLOWING STAR                        6189\n",
       "HEAVY CHECK MARK                    5911\n",
       "Name: Unicode name, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the distribution of emojis\n",
    "tweets_emojis['Unicode name'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send tweets as input to the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# classify emoji emotions and save in new column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tweets_emojis[\u001b[39m'\u001b[39m\u001b[39mEmotions\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tweets_emojis[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m names: get_emotion(names\u001b[39m.\u001b[39;49mlower()))\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(names)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# classify emoji emotions and save in new column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tweets_emojis[\u001b[39m'\u001b[39m\u001b[39mEmotions\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tweets_emojis[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m names: get_emotion(names\u001b[39m.\u001b[39;49mlower()))\n",
      "Cell \u001b[1;32mIn[43], line 9\u001b[0m, in \u001b[0;36mget_emotion\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_emotion\u001b[39m(text):\n\u001b[0;32m      7\u001b[0m   input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(text \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m</s>\u001b[39m\u001b[39m'\u001b[39m, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m   output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m     10\u001b[0m                max_length\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m   dec \u001b[39m=\u001b[39m [tokenizer\u001b[39m.\u001b[39mdecode(ids) \u001b[39mfor\u001b[39;00m ids \u001b[39min\u001b[39;00m output]\n\u001b[0;32m     13\u001b[0m   label \u001b[39m=\u001b[39m dec[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\generation\\utils.py:1518\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1514\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1, but is \u001b[39m\u001b[39m{\u001b[39;00mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m when doing greedy search.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1515\u001b[0m         )\n\u001b[0;32m   1517\u001b[0m     \u001b[39m# 10. run greedy search\u001b[39;00m\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[0;32m   1519\u001b[0m         input_ids,\n\u001b[0;32m   1520\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[0;32m   1521\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[0;32m   1522\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[0;32m   1523\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[0;32m   1524\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[0;32m   1525\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[0;32m   1526\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[0;32m   1527\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m   1528\u001b[0m     )\n\u001b[0;32m   1530\u001b[0m \u001b[39melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[0;32m   1532\u001b[0m     \u001b[39mif\u001b[39;00m num_return_sequences \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\generation\\utils.py:2285\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2282\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2284\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2285\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[0;32m   2286\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[0;32m   2287\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   2288\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   2289\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   2290\u001b[0m )\n\u001b[0;32m   2292\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2293\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1648\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1645\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[0;32m   1647\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[1;32m-> 1648\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[0;32m   1649\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[0;32m   1650\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[0;32m   1651\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[0;32m   1652\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1653\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m   1654\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1655\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[0;32m   1656\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[0;32m   1657\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1658\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1659\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1660\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1661\u001b[0m )\n\u001b[0;32m   1663\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1665\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1040\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1027\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[0;32m   1028\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m   1029\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m     )\n\u001b[0;32m   1039\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1040\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m   1041\u001b[0m         hidden_states,\n\u001b[0;32m   1042\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1043\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m   1044\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1045\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1046\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[0;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[0;32m   1049\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m   1050\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1051\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1052\u001b[0m     )\n\u001b[0;32m   1054\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:699\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    697\u001b[0m     query_length \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 699\u001b[0m cross_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m1\u001b[39;49m](\n\u001b[0;32m    700\u001b[0m     hidden_states,\n\u001b[0;32m    701\u001b[0m     key_value_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    702\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m    703\u001b[0m     position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[0;32m    704\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[0;32m    705\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mcross_attn_past_key_value,\n\u001b[0;32m    706\u001b[0m     query_length\u001b[39m=\u001b[39;49mquery_length,\n\u001b[0;32m    707\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    708\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    709\u001b[0m )\n\u001b[0;32m    710\u001b[0m hidden_states \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    712\u001b[0m \u001b[39m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:613\u001b[0m, in \u001b[0;36mT5LayerCrossAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    601\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    602\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    610\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    611\u001b[0m ):\n\u001b[0;32m    612\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 613\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mEncDecAttention(\n\u001b[0;32m    614\u001b[0m         normed_hidden_states,\n\u001b[0;32m    615\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    616\u001b[0m         key_value_states\u001b[39m=\u001b[39;49mkey_value_states,\n\u001b[0;32m    617\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m    618\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    619\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m    620\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    621\u001b[0m         query_length\u001b[39m=\u001b[39;49mquery_length,\n\u001b[0;32m    622\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    623\u001b[0m     )\n\u001b[0;32m    624\u001b[0m     layer_output \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[0;32m    625\u001b[0m     outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:504\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[39m# get key/value states\u001b[39;00m\n\u001b[0;32m    501\u001b[0m key_states \u001b[39m=\u001b[39m project(\n\u001b[0;32m    502\u001b[0m     hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk, key_value_states, past_key_value[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    503\u001b[0m )\n\u001b[1;32m--> 504\u001b[0m value_states \u001b[39m=\u001b[39m project(\n\u001b[0;32m    505\u001b[0m     hidden_states, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv, key_value_states, past_key_value[\u001b[39m1\u001b[39;49m] \u001b[39mif\u001b[39;49;00m past_key_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[39m# compute scores\u001b[39;00m\n\u001b[0;32m    509\u001b[0m scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(\n\u001b[0;32m    510\u001b[0m     query_states, key_states\u001b[39m.\u001b[39mtranspose(\u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m    511\u001b[0m )  \u001b[39m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:485\u001b[0m, in \u001b[0;36mT5Attention.forward.<locals>.project\u001b[1;34m(hidden_states, proj_layer, key_value_states, past_key_value)\u001b[0m\n\u001b[0;32m    481\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(hidden_states))\n\u001b[0;32m    482\u001b[0m \u001b[39melif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m     \u001b[39m# cross-attn\u001b[39;00m\n\u001b[0;32m    484\u001b[0m     \u001b[39m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(key_value_states))\n\u001b[0;32m    487\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m key_value_states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m         \u001b[39m# self-attn\u001b[39;00m\n\u001b[0;32m    490\u001b[0m         \u001b[39m# (batch_size, n_heads, key_length, dim_per_head)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lujai\\anaconda3\\envs\\capstone-proj\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:470\u001b[0m, in \u001b[0;36mT5Attention.forward.<locals>.shape\u001b[1;34m(states)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshape\u001b[39m(states):\n\u001b[0;32m    469\u001b[0m     \u001b[39m\"\"\"projection\"\"\"\u001b[39;00m\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mreturn\u001b[39;00m states\u001b[39m.\u001b[39;49mview(batch_size, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_heads, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_value_proj_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# classify emoji emotions and save in new column\n",
    "tweets_emojis['Emotions'] = tweets_emojis['text'].apply(lambda names: get_emotion(names.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete extra word present at the start of the string\n",
    "tweets_emojis['Emotions'] = tweets_emojis['Emotions'].apply(lambda names: names.split(' ', 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Unicode name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Idk who taught my baby this BS  Ô∏è  IGmeetthesa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Thats me in every lesson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Partner strategy LLRC  Urban naxal theories ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Dont play with me  üèæ ‚Äç  Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>To the goofiest boy ever who apparently looks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Real Real cuz these niggas really b bluffing s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>‚Äú What the heck I ordered an Xbox card ‚Äù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>thread is absolutely outstanding  Silage of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>how can you say you love her if you cant even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Whats wrong with females these days  üèæ ‚Äç  Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Having to pick it up is what really blows me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>This man is hilariously entertaining to me amp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>im not ready for kids im crying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Retweet or 7 years bad luck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>If it snows tomorrow jus be ready to see it on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>This is the best Hindi parody I ever heard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>I mean what do I say to this Ok Keira I wont s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>The struggles of liking it raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>My ass is staying in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Fragrance of baby powder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emoji            Unicode name  \\\n",
       "0      üòÇ  FACE WITH TEARS OF JOY   \n",
       "1      üòÇ  FACE WITH TEARS OF JOY   \n",
       "2      üòÇ  FACE WITH TEARS OF JOY   \n",
       "3      üòÇ  FACE WITH TEARS OF JOY   \n",
       "4      üòÇ  FACE WITH TEARS OF JOY   \n",
       "5      üòÇ  FACE WITH TEARS OF JOY   \n",
       "6      üòÇ  FACE WITH TEARS OF JOY   \n",
       "7      üòÇ  FACE WITH TEARS OF JOY   \n",
       "8      üòÇ  FACE WITH TEARS OF JOY   \n",
       "9      üòÇ  FACE WITH TEARS OF JOY   \n",
       "10     üòÇ  FACE WITH TEARS OF JOY   \n",
       "11     üòÇ  FACE WITH TEARS OF JOY   \n",
       "12     üòÇ  FACE WITH TEARS OF JOY   \n",
       "13     üòÇ  FACE WITH TEARS OF JOY   \n",
       "14     üòÇ  FACE WITH TEARS OF JOY   \n",
       "15     üòÇ  FACE WITH TEARS OF JOY   \n",
       "16     üòÇ  FACE WITH TEARS OF JOY   \n",
       "17     üòÇ  FACE WITH TEARS OF JOY   \n",
       "18     üòÇ  FACE WITH TEARS OF JOY   \n",
       "19     üòÇ  FACE WITH TEARS OF JOY   \n",
       "\n",
       "                                                 text  \n",
       "0   Idk who taught my baby this BS  Ô∏è  IGmeetthesa...  \n",
       "1                           Thats me in every lesson   \n",
       "2   Partner strategy LLRC  Urban naxal theories ar...  \n",
       "3                          Dont play with me  üèæ ‚Äç  Ô∏è   \n",
       "4   To the goofiest boy ever who apparently looks ...  \n",
       "5   Real Real cuz these niggas really b bluffing s...  \n",
       "6           ‚Äú What the heck I ordered an Xbox card ‚Äù   \n",
       "7   thread is absolutely outstanding  Silage of th...  \n",
       "8   how can you say you love her if you cant even ...  \n",
       "9         Whats wrong with females these days  üèæ ‚Äç  Ô∏è  \n",
       "10  Having to pick it up is what really blows me t...  \n",
       "11  This man is hilariously entertaining to me amp...  \n",
       "12                   im not ready for kids im crying   \n",
       "13                       Retweet or 7 years bad luck   \n",
       "14  If it snows tomorrow jus be ready to see it on...  \n",
       "15        This is the best Hindi parody I ever heard   \n",
       "16  I mean what do I say to this Ok Keira I wont s...  \n",
       "17                    The struggles of liking it raw   \n",
       "18                              My ass is staying in   \n",
       "19                          Fragrance of baby powder   "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_emojis.head(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Unicode name</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚ù§</td>\n",
       "      <td>HEAVY BLACK HEART</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‚ô•</td>\n",
       "      <td>BLACK HEART SUIT</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòç</td>\n",
       "      <td>SMILING FACE WITH HEART-SHAPED EYES</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üò≠</td>\n",
       "      <td>LOUDLY CRYING FACE</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>üòò</td>\n",
       "      <td>FACE THROWING A KISS</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>üòä</td>\n",
       "      <td>SMILING FACE WITH SMILING EYES</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>üëå</td>\n",
       "      <td>OK HAND SIGN</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>üíï</td>\n",
       "      <td>TWO HEARTS</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>üëè</td>\n",
       "      <td>CLAPPING HANDS SIGN</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>üòÅ</td>\n",
       "      <td>GRINNING FACE WITH SMILING EYES</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>‚ò∫</td>\n",
       "      <td>WHITE SMILING FACE</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>‚ô°</td>\n",
       "      <td>WHITE HEART SUIT</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>üëç</td>\n",
       "      <td>THUMBS UP SIGN</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>üò©</td>\n",
       "      <td>WEARY FACE</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>üôè</td>\n",
       "      <td>PERSON WITH FOLDED HANDS</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>‚úå</td>\n",
       "      <td>VICTORY HAND</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>üòè</td>\n",
       "      <td>SMIRKING FACE</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>üòâ</td>\n",
       "      <td>WINKING FACE</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>üôå</td>\n",
       "      <td>PERSON RAISING BOTH HANDS IN CELEBRATION</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emoji                              Unicode name Emotions\n",
       "0      üòÇ                    FACE WITH TEARS OF JOY      joy\n",
       "1      ‚ù§                         HEAVY BLACK HEART  sadness\n",
       "2      ‚ô•                          BLACK HEART SUIT    anger\n",
       "3      üòç       SMILING FACE WITH HEART-SHAPED EYES      joy\n",
       "4      üò≠                        LOUDLY CRYING FACE    anger\n",
       "5      üòò                      FACE THROWING A KISS     fear\n",
       "6      üòä            SMILING FACE WITH SMILING EYES      joy\n",
       "7      üëå                              OK HAND SIGN      joy\n",
       "8      üíï                                TWO HEARTS    anger\n",
       "9      üëè                       CLAPPING HANDS SIGN    anger\n",
       "10     üòÅ           GRINNING FACE WITH SMILING EYES      joy\n",
       "11     ‚ò∫                        WHITE SMILING FACE      joy\n",
       "12     ‚ô°                          WHITE HEART SUIT      joy\n",
       "13     üëç                            THUMBS UP SIGN    anger\n",
       "14     üò©                                WEARY FACE  sadness\n",
       "15     üôè                  PERSON WITH FOLDED HANDS     fear\n",
       "16     ‚úå                              VICTORY HAND      joy\n",
       "17     üòè                             SMIRKING FACE    anger\n",
       "18     üòâ                              WINKING FACE     fear\n",
       "19     üôå  PERSON RAISING BOTH HANDS IN CELEBRATION      joy"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis.head(20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge emoji and emotion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_train = pd.read_csv(\"../data/emotions/train.txt\", delimiter=';', header=None, names=['Sentence','Emotions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Emotions\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first 5 rows\n",
    "emotion_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_emojis = tweets_emojis[['Emoji', 'Emotions']]\n",
    "tweets_emojis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚ù§</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‚ô•</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòç</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üò≠</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emoji Emotions\n",
       "0     üòÇ      joy\n",
       "1     ‚ù§  sadness\n",
       "2     ‚ô•    anger\n",
       "3     üòç      joy\n",
       "4     üò≠    anger"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis = emojis[['Emoji', 'Emotions']]\n",
    "emojis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two tables on 'Emotion' column\n",
    "emotion_emoji_merged = emotion_train.merge(tweets_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üò©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üíú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üíô</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üò¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üòû</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üò´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üíî</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üòë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üéÖ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üéÑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üçÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üòø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üí®</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üòß</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>‚ñì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üôÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üíü</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üíä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>üåå</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Sentence Emotions Emoji\n",
       "0   i didnt feel humiliated  sadness     ‚ù§\n",
       "1   i didnt feel humiliated  sadness     üò©\n",
       "2   i didnt feel humiliated  sadness     üíú\n",
       "3   i didnt feel humiliated  sadness     üíô\n",
       "4   i didnt feel humiliated  sadness     üò¢\n",
       "5   i didnt feel humiliated  sadness     üòû\n",
       "6   i didnt feel humiliated  sadness     üò´\n",
       "7   i didnt feel humiliated  sadness     üíî\n",
       "8   i didnt feel humiliated  sadness     üòë\n",
       "9   i didnt feel humiliated  sadness     üéÖ\n",
       "10  i didnt feel humiliated  sadness     üéÑ\n",
       "11  i didnt feel humiliated  sadness     üçÇ\n",
       "12  i didnt feel humiliated  sadness     üòø\n",
       "13  i didnt feel humiliated  sadness     üí®\n",
       "14  i didnt feel humiliated  sadness     üòß\n",
       "15  i didnt feel humiliated  sadness     ‚ñì\n",
       "16  i didnt feel humiliated  sadness     üôÄ\n",
       "17  i didnt feel humiliated  sadness     üíü\n",
       "18  i didnt feel humiliated  sadness     üíä\n",
       "19  i didnt feel humiliated  sadness     üåå"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_emoji_merged.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2801783, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_emoji_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Text emoji recommendation\n",
    "In this lat part, we train a new model to take the text and recommends an emoji based on that text. The feature is the text and the target variable is the emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing require Libraries\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from tkinter import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.python import keras\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM ,Conv2D, Dense,GlobalAveragePooling1D,Flatten, Dropout , GRU, TimeDistributed, Conv1D, MaxPool1D, MaxPool2D, Bidirectional\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "##\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an embedding matrix using the golve vectors (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y_train to one hot vectors so that cross-entropy loss can be used\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(units = 256, return_sequences=True, input_shape = (168,50)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=20, activation='relu'))\n",
    "model.add(Dense(units=20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['acc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.fit(X_temb, y_train, validation_split=0.2, batch_size=32, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and accuracy plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix and correlation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('capstone-proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11b89a8208dc62c4b368a2fc84cebd8a1aafdd7a9e7b8f254ebc1eaaea760d8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
